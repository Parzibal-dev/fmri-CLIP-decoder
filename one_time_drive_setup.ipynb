{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f76404",
   "metadata": {},
   "source": [
    "Just a script to embed all of the textual and image data in CLIP and save the embeddings in the drive folder\n",
    "Requires the image data to be unzipped, and all .ini files do be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed2fd7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81937104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to c:\\users\\talgo\\appdata\\local\\temp\\pip-req-build-1e2s8d6x\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ftfy in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (2025.7.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from clip==1.0) (0.23.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch->clip==1.0) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision->clip==1.0) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torchvision->clip==1.0) (11.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm->clip==1.0) (0.4.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git 'C:\\Users\\talgo\\AppData\\Local\\Temp\\pip-req-build-1e2s8d6x'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\talgo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff134b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\talgo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\talgo\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3634030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- stdlib & deps ------------------------------------------------------\n",
    "import os, sys, numpy as np, torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "from dotenv import load_dotenv\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# ----- get project dir from env -----\n",
    "load_dotenv()  # this loads variables from .env into os.environ\n",
    "\n",
    "BRAIN_DECODER_DIR = os.environ.get(\"BRAIN_DECODER_DIR\")\n",
    "if not BRAIN_DECODER_DIR:\n",
    "    raise EnvironmentError(\n",
    "        \"BRAIN_DECODER_DIR is not set in your .env file.\\n\"\n",
    "        \"Please add it, e.g.:\\nBRAIN_DECODER_DIR=G:/My Drive/brain-decoder-files\"\n",
    "    )\n",
    "\n",
    "# ----- paths --------------------------------------------------------------\n",
    "PROJ_DIR = Path.cwd()\n",
    "DATA_DIR = PROJ_DIR / \"data\"\n",
    "DRIVE_DATA_FOLDER = Path(BRAIN_DECODER_DIR).expanduser().resolve()\n",
    "if not DRIVE_DATA_FOLDER.exists():\n",
    "    raise FileNotFoundError(f\"Project directory not found: {DRIVE_DATA_FOLDER}\")\n",
    "\n",
    "text_npz   = DRIVE_DATA_FOLDER / \"clip_text_embeddings.npz\"\n",
    "image_npz  = DRIVE_DATA_FOLDER / \"clip_image_embeddings.npz\"   # new: raw vectors\n",
    "images_dir = DATA_DIR / \"experiment-images\"\n",
    "assert images_dir.is_dir(), f\"{images_dir} not found!\"\n",
    "\n",
    "# ----- load CLIP model ----------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)  # returns 768-d vectors\n",
    "model.eval()\n",
    "\n",
    "# ----- concept labels -----------------------------------------------------\n",
    "concepts = np.genfromtxt(DRIVE_DATA_FOLDER / \"concepts.txt\", dtype=str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061a044",
   "metadata": {},
   "source": [
    "### Embed textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    toks = clip.tokenize([f\"A photo of {c}\" for c in concepts]).to(device)\n",
    "    txt  = model.encode_text(toks)\n",
    "    txt  = txt / txt.norm(dim=-1, keepdim=True)\n",
    "\n",
    "np.savez_compressed(text_npz, data=txt.cpu().numpy().astype(np.float32))\n",
    "print(\"Text vectors saved to\", text_npz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a910b8",
   "metadata": {},
   "source": [
    "### Embed image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe96c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding images: 100%|██████████| 17/17 [36:01<00:00, 127.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image vectors saved to  G:\\.shortcut-targets-by-id\\1CwmFOsYFnq6t33KAzpvw0gaOTQXbcozs\\brain-decoder-files\\clip_image_embeddings.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_paths = [(con, p) for con in concepts for p in (images_dir / con).glob(\"*.jpg\")]\n",
    "\n",
    "BATCH = 64\n",
    "all_vecs, all_cons, all_files = [], [], []\n",
    "\n",
    "for i in tqdm(range(0, len(img_paths), BATCH), desc=\"encoding images\"):\n",
    "    batch_paths = img_paths[i : i + BATCH]\n",
    "\n",
    "    imgs = [preprocess(Image.open(p).convert(\"RGB\")) for _, p in batch_paths]\n",
    "    imgs = torch.stack(imgs).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vecs = model.encode_image(imgs).float()\n",
    "    vecs = vecs / vecs.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    all_vecs.append(vecs.cpu())\n",
    "    all_cons.extend([con for con, _ in batch_paths])\n",
    "    all_files.extend([p.name for _, p in batch_paths])\n",
    "\n",
    "embeddings = torch.cat(all_vecs).numpy().astype(np.float32)\n",
    "\n",
    "np.savez_compressed(\n",
    "    image_npz,\n",
    "    embeddings=embeddings,\n",
    "    concepts=np.array(all_cons),\n",
    "    filenames=np.array(all_files),\n",
    ")\n",
    "print(f\"Image vectors saved to \", image_npz)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
